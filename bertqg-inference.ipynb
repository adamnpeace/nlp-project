{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4527325b-8871-40d3-8c2c-62084f444907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle, time, random, logging, json, gc, warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import AdamW, BertConfig, BertTokenizer\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import EncoderDecoderModel\n",
    "from transformers import BertModel\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.translate import bleu\n",
    "import spacy\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f3b31d3-7a08-41dd-93df-8c9ee4b2f3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb4b3e2c-24ea-4920-8639-169520b28169",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = 'bert-large-uncased'\n",
    "model_path = Path('./models')\n",
    "data_path = Path('.')\n",
    "bert_path = model_path / bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cde4ef04-7776-494c-9f20-de09c7821932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]: models/21-05-10-1316-bert-large-uncased\n",
      "[2]: models/21-05-10-1610-bert-large-uncased\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Which Model do you want? 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen models/21-05-10-1610-bert-large-uncased\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'num_workers': '0',\n",
       " 'pin_memory': 'False',\n",
       " 'batch_size': '4',\n",
       " 'weight_decay': '0.001',\n",
       " 'lr': '0.05',\n",
       " 'momentum': '0.9',\n",
       " 'decoder_hidden_size': '512',\n",
       " 'decoder_input_size': '512',\n",
       " 'attention_hidden_size': '512',\n",
       " 'max_input_length': '512',\n",
       " 'n_layers': '1',\n",
       " 'clip': '1',\n",
       " 'dropout': '1',\n",
       " 'n_epochs': '4',\n",
       " 'max_epochs': '32',\n",
       " 'patience': '2',\n",
       " 'mb': '32',\n",
       " 'checkpoint': 'None',\n",
       " 'encoder_trained': 'False',\n",
       " 'pw_criterion': 'CrossEntropyLoss()',\n",
       " 'bert_model': 'bert-large-uncased',\n",
       " 'tokenizer': \"PreTrainedTokenizer(name_or_path='bert-large-uncased', vocab_size=30522, model_max_len=512, is_fast=False, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\",\n",
       " 'bert_path': 'models/bert-large-uncased',\n",
       " 'bert_hidden_size': '1024',\n",
       " 'bert_vocab_size': '30522'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_paths = []\n",
    "for i, x in enumerate(model_path.glob('*-{}'.format(bert_model))):\n",
    "    if (x / 'best_model.pt').exists():\n",
    "        model_paths.append(x)\n",
    "        print('[{}]: {}'.format(len(model_paths), x))\n",
    "        \n",
    "idx = int(input('Which Model do you want?')) - 1\n",
    "model_save_dir = model_paths[idx]\n",
    "print(\"Chosen {}\".format(model_save_dir))\n",
    "json.load(open(model_save_dir / 'hp.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8462296d-fcb9-467f-9133-7383e0bbc01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HP:\n",
    "    def __init__(self):\n",
    "        self.num_workers = 0\n",
    "        self.pin_memory = False\n",
    "        self.batch_size = 4\n",
    "        self.weight_decay = 0.001\n",
    "        self.lr = 0.05\n",
    "        self.adam_lr = 0.001\n",
    "        self.momentum = 0.9\n",
    "        self.decoder_hidden_size = 512\n",
    "        self.decoder_input_size = 512\n",
    "        self.attention_hidden_size = 512\n",
    "        self.max_input_length = 512\n",
    "        self.n_layers = 1\n",
    "        self.clip = 1\n",
    "        self.dropout = 1\n",
    "        self.n_epochs = 4\n",
    "        self.max_epochs = 32\n",
    "        self.patience = 3\n",
    "        self.mb = 32\n",
    "        self.checkpoint = None\n",
    "        self.encoder_trained = False\n",
    "        \n",
    "        conf_file = json.load(open((bert_path / 'config.json'), 'r'))\n",
    "        self.bert_hidden_size = conf_file['hidden_size']\n",
    "        self.bert_vocab_size = conf_file['vocab_size']\n",
    "        \n",
    "        \n",
    "hp = HP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84f38c5d-2bc6-409a-8121-dad3a7fd9b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HP:\n",
    "    def __init__(self):\n",
    "        self.num_workers = 0\n",
    "        self.pin_memory = False\n",
    "        self.batch_size = 4\n",
    "        self.weight_decay = 0.001\n",
    "        self.lr = 0.05\n",
    "        self.momentum = 0.9\n",
    "        self.decoder_hidden_size = 1024\n",
    "        self.decoder_input_size = 1024\n",
    "        self.attention_hidden_size = 1024\n",
    "        self.max_input_length = 1024\n",
    "        self.n_layers = 1\n",
    "        self.clip = 1\n",
    "        self.dropout = 1\n",
    "        self.n_epochs = 4\n",
    "        self.max_epochs = 32\n",
    "        self.patience = 3\n",
    "        self.mb = 32\n",
    "        self.checkpoint = None\n",
    "        self.encoder_trained = False\n",
    "\n",
    "        self.pw_criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "        self.bert_model = 'bert-large-uncased'\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(self.bert_model)\n",
    "        \n",
    "        self.bert_path = model_path / self.bert_model\n",
    "\n",
    "        if not (model_path / self.bert_model / 'config.json').is_file():\n",
    "            BertModel.from_pretrained(self.bert_model).save_pretrained(model_path / self.bert_model)\n",
    "        conf_file = json.load(open((self.bert_path / 'config.json'), 'r'))\n",
    "        self.bert_hidden_size = conf_file['hidden_size']\n",
    "        self.bert_vocab_size = conf_file['vocab_size']\n",
    "        \n",
    "hp = HP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdbc4d44-06c1-4eda-b297-3fcb8b3c6a01",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164,
     "referenced_widgets": [
      "8e5ad8edc0f74115985c8f37de08a471",
      "07372b34febc41c4a8821dc7b3eee611",
      "42b3d26eff834c89b04d5f384e72f4d4",
      "6dfa1ad561d64d528e28b6eee5b67438",
      "3b5f203474e045d0a4ffabba84cd1f5d",
      "b047f00ed189467c8335ee891052e179",
      "bbc936f085e74e14ab1de23ab30227bd",
      "3425e5aa9f254befb5b4f67543ec701e",
      "0c17b6e060b04e35bca10dccd723e4e7",
      "18a6edffa2c545779dffdc98041f70b0",
      "acfda85a52e0422da6b76aeed3805094",
      "3c0b5ad218ae4d9dac090cb7b7fe5c1a",
      "380b27f68a3c42f78a3feb77d7e95b6f",
      "b1456557c06742eb85b695be09c110ab",
      "78aa5c8513c14e4480726e505f07f006",
      "1e6f29561f0f4acd8926e3ab0397c5ac",
      "17856846895b4cd4a0d97d81b895d52e",
      "ac21ed8164ff45cf9c4d2c80a3f80761",
      "c055349cad414740b1a0de8f220ef171",
      "256d40052ee949628a11d69329efc38a",
      "2e42f68fc9ed4c21b824882f9f6bcd65",
      "ed01efea6bbe4ec1addf061a960cd3b8",
      "b2f40178a49649228ca61911a03772cb",
      "11a26dbb4d1a43c5a5f3d49164143a2e"
     ]
    },
    "id": "c51e0d74-7cb0-4334-85fc-676ab4d4212c",
    "outputId": "5482fc8f-38e7-4424-e173-c6d29548f523"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(bert_model)\n",
    "\n",
    "def bleu_score(prediction, ground_truth):\n",
    "    prediction = prediction.max(2)[1]\n",
    "    acc_bleu = 0\n",
    "\n",
    "    for x, y in zip(ground_truth, prediction):\n",
    "        x = tokenizer.convert_ids_to_tokens(x.tolist())\n",
    "        y = tokenizer.convert_ids_to_tokens(y.tolist())\n",
    "        idx1 = x.index('[PAD]') if '[PAD]' in x else len(x)\n",
    "        idx2 = y.index('[SEP]') if '[SEP]' in y else len(y)\n",
    "\n",
    "        acc_bleu += bleu([x[1:idx1 - 1]], y[1:idx2 - 1], smoothing_function=SmoothingFunction().method4)\n",
    "    return acc_bleu / prediction.size(0)\n",
    "\n",
    "def eval(model, dataloader, criterion):\n",
    "    log = logging.getLogger(__name__)\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_bleu = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i, (input_, output_) in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "\n",
    "            input_data, input_length = input_\n",
    "            output_data, output_length = output_\n",
    "\n",
    "            prediction = model([x.to(device) for x in input_data], output_data.to(device), 0)  # turn off teacher forcing\n",
    "\n",
    "            sample_t = tokenizer.convert_ids_to_tokens(output_data[0].tolist())\n",
    "            sample_p = tokenizer.convert_ids_to_tokens(prediction[0].max(1)[1].tolist())\n",
    "            idx1 = sample_t.index('[PAD]') if '[PAD]' in sample_t else len(sample_t)\n",
    "            idx2 = sample_p.index('[SEP]') if '[SEP]' in sample_p else len(sample_p)\n",
    "\n",
    "            bleu_i = bleu_score(prediction, output_data.to(device))\n",
    "\n",
    "            trg_sent_len = prediction.size(1)\n",
    "            # trg = [trg sent len, batch size]\n",
    "            # output = [trg sent len, batch size, output dim]\n",
    "\n",
    "            prediction = prediction[:, 1:].contiguous().view(-1, prediction.shape[-1])\n",
    "            output_data = output_data[:, 1:].contiguous().view(-1)  # Find a way to avoid calling contiguous\n",
    "\n",
    "            # trg = [(trg sent len - 1) * batch size]\n",
    "            # output = [(trg sent len - 1) * batch size, output dim]\n",
    "\n",
    "            pw_loss = hp.pw_criterion(prediction, output_data.to(device))\n",
    "\n",
    "            loss = criterion(prediction, output_data.to(device))\n",
    "            loss = loss.view(-1, trg_sent_len - 1)\n",
    "            loss = loss.sum(1)\n",
    "            loss = loss.mean(0)\n",
    "\n",
    "            if i % int(len(dataloader) * 0.1) == int(len(dataloader) * 0.1) - 1:\n",
    "                print('Batch {}: Sentence Loss: {:.3f}, Word Loss: {:.3f}, BLEU score {:.4f}'.format(i, loss.item(), pw_loss.item(), bleu_i))\n",
    "\n",
    "                print(\n",
    "                    'Target -> {}\\nPrediction -> {}\\n\\n'.format(\n",
    "                        sample_t[1:idx1-1], sample_p[1:idx2-1]\n",
    "                    ))\n",
    "            epoch_loss += pw_loss.item()\n",
    "            epoch_bleu += bleu_i\n",
    "\n",
    "        return epoch_loss / len(dataloader), epoch_bleu / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f67984e8-1135-454a-bfe9-59f557ab50d9",
   "metadata": {
    "id": "5f214c24-992a-45e9-9d03-fbbb9bf22722",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BertDataset(Dataset):\n",
    "    def __init__(self, json_path, bert_model):\n",
    "        all_data = json.load(open(json_path, 'r'))\n",
    "        input, output = self._extract_data(all_data)\n",
    "        self.data = self._tokenize_data(input, output, bert_model)\n",
    "\n",
    "    def _extract_data(self, all_data):\n",
    "        input, output = [], []\n",
    "        for data in all_data:\n",
    "            input.append((data['passages'], data['responses']))\n",
    "            output.append(data['clues'])\n",
    "        input, output = input[:-1], output[:-1]\n",
    "        return input, output\n",
    "\n",
    "    def _tokenize_data(self, input, output, bert_model):\n",
    "        tokenizer = BertTokenizer.from_pretrained(bert_model)\n",
    "        \n",
    "        data = tokenizer.batch_encode_plus(input, pad_to_max_length=True, return_tensors='pt')\n",
    "        out_dict = tokenizer.batch_encode_plus(output, pad_to_max_length=True, return_tensors='pt')\n",
    "        \n",
    "        data['output_ids'] = out_dict['input_ids']\n",
    "        data['output_len'] = out_dict['attention_mask'].sum(dim=1)\n",
    "        data['input_len'] = data['attention_mask'].sum(dim=1)\n",
    "        \n",
    "        idx = (data['input_len'] <= hp.max_input_length)\n",
    "        in_m = max(data['input_len'][idx])\n",
    "        out_m = max(data['output_len'][idx])\n",
    "        \n",
    "        data['input_ids'] = data['input_ids'][idx, :in_m]\n",
    "        data['attention_mask'] = data['attention_mask'][idx, :in_m]\n",
    "        data['token_type_ids'] = data['token_type_ids'][idx, :in_m]\n",
    "        data['input_len'] = data['input_len'][idx]\n",
    "        \n",
    "        data['output_ids'] = data['output_ids'][idx, :out_m]\n",
    "        data['output_len'] = data['output_len'][idx]\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data['input_ids'].shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (((self.data['input_ids'][idx],\n",
    "                self.data['attention_mask'][idx],\n",
    "                self.data['token_type_ids'][idx]),\n",
    "                self.data['input_len'][idx]),\n",
    "                (self.data['output_ids'][idx],\n",
    "                self.data['output_len'][idx])\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbe14e70-7028-4f95-86f5-2596e1fdadfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_set = BertDataset('data_dev.json', bert_model)\n",
    "\n",
    "dev_loader = DataLoader(dev_set, batch_size=hp.batch_size, shuffle=True,\n",
    "                        num_workers=hp.num_workers, pin_memory=hp.pin_memory\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7d4624d-803d-419d-848b-aea33874e685",
   "metadata": {
    "id": "610d0ea5-84b9-4b23-96cf-ecf9694387f2"
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, n_h_enc, n_h_dec, n_h_attention):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(n_h_enc + n_h_dec, n_h_attention)\n",
    "        self.v = nn.Parameter(torch.rand(n_h_attention), requires_grad=True)\n",
    "        \n",
    "    def forward(self, key, queries):\n",
    "        batch_size, src_len = queries.shape[:2]\n",
    "        \n",
    "        key = key.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        if key.size(0) != queries.size(0) or key.size(1) != queries.size(1):\n",
    "            print(key.shape, queries.shape)\n",
    "        kitten = torch.cat((key, queries), dim=2)\n",
    "        energy = torch.tanh(self.attn(kitten))\n",
    "        \n",
    "        v = self.v.repeat(batch_size, 1).unsqueeze(2)\n",
    "        \n",
    "        attn = torch.bmm(energy, v).squeeze(2)\n",
    "        \n",
    "        return F.softmax(attn, dim=1)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, out_dims, emb_dims, n_h_enc, n_h_dec, n_layers, dropout, attn):\n",
    "        super().__init__()\n",
    "        self.out_dims = out_dims\n",
    "        self.emb_dims = emb_dims\n",
    "        self.n_h_enc = n_h_enc\n",
    "        self.n_h_dec = n_h_dec\n",
    "        self.n_layers = n_layers\n",
    "        self.attn = attn\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.embedding = nn.Embedding(out_dims, emb_dims)\n",
    "        \n",
    "        self.rnn = nn.GRU(emb_dims, n_h_dec, batch_first=True, num_layers=n_layers, dropout=dropout)\n",
    "\n",
    "        self.out_dense = nn.Linear(n_h_enc + n_h_dec, out_dims)\n",
    "        \n",
    "    def forward(self, src, queries, hidden):\n",
    "        src = src.unsqueeze(1)\n",
    "        embedded = self.embedding(src)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        out, hidden = self.rnn(embedded, hidden)\n",
    "        out = out.squeeze()\n",
    "        \n",
    "        a = self.attn(out, queries)\n",
    "        a = a.unsqueeze(1)\n",
    "        weighted = torch.bmm(a, queries)\n",
    "        \n",
    "        weighted = weighted.squeeze(1)\n",
    "        \n",
    "        out = self.out_dense(torch.cat([out, weighted], dim=1))\n",
    "        \n",
    "        return out, hidden\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, encoder_trained):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.encoder_trained = encoder_trained\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        input_ids, token_ids, attn_mask = src\n",
    "        \n",
    "        if self.encoder_trained:\n",
    "            bert_hs = self.encoder(input_ids, token_type_ids=token_ids, attention_mask=attn_mask)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                bert_hs = self.encoder(input_ids, token_type_ids=token_ids, attention_mask=attn_mask)\n",
    "        \n",
    "        bert_encodings = bert_hs[0]\n",
    "        \n",
    "        batch_size, max_len = trg.shape[:2]\n",
    "        \n",
    "        trg_vocab_size = self.decoder.out_dims\n",
    "        \n",
    "        outputs = torch.zeros(batch_size, max_len, trg_vocab_size).to(device)\n",
    "        \n",
    "        out = trg[:, 0]\n",
    "        \n",
    "        hidden = torch.zeros(self.decoder.n_layers, out.shape[0], self.decoder.n_h_dec).to(device)\n",
    "        \n",
    "        for t in range(1, max_len):\n",
    "            out, hidden = self.decoder(out, bert_encodings, hidden)\n",
    "            outputs[:, t] = out\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            out = (trg[:, t] if teacher_force else out.max(1)[1])\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba981f97-7c29-484d-82b8-e5118edbe7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(model_save_dir / 'best_model.pt')\n",
    "\n",
    "model.to(device);\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0, reduction='none')\n",
    "\n",
    "dev_loss, bleu_score_i = eval(model, dev_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d3d87f-7a56-4abf-9eb3-502135ac7480",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QA-nlp",
   "language": "python",
   "name": "qa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
