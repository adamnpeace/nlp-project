{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "QA-nlp",
      "language": "python",
      "name": "qa"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "bertqg.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "niSDQPa-GPyt",
        "outputId": "cb76ccf8-f307-43bf-e28e-e32943647b08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "id": "niSDQPa-GPyt",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws84SMCIGvqN",
        "outputId": "ada55843-7217-4cc7-d7a5-2ef7402d6d8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "id": "Ws84SMCIGvqN",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun May  9 21:49:37 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    24W / 300W |      2MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25529b09-0de3-43a5-a398-c2424a2b8334"
      },
      "source": [
        "import os, pickle, time, random, logging, json, gc, warnings\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from transformers import AdamW, BertConfig, BertTokenizer\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from transformers import EncoderDecoderModel\n",
        "from transformers import BertModel\n",
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "import spacy\n",
        "\n",
        "warnings.simplefilter(\"ignore\")"
      ],
      "id": "25529b09-0de3-43a5-a398-c2424a2b8334",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dd9406b-bd64-4435-98c1-d1af433684ba"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "id": "3dd9406b-bd64-4435-98c1-d1af433684ba",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8840c32c-6845-4206-a8ba-6a688e9f1abd",
        "outputId": "c5d73c3d-6206-4f24-c9a4-1f31c46137a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/adamnpeace/nlp-project/model-testing-bertqg/data/preprocessed/data_dev.json\n",
        "!wget https://raw.githubusercontent.com/adamnpeace/nlp-project/model-testing-bertqg/data/preprocessed/data_train.json"
      ],
      "id": "8840c32c-6845-4206-a8ba-6a688e9f1abd",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-09 21:48:37--  https://raw.githubusercontent.com/adamnpeace/nlp-project/model-testing-bertqg/data/preprocessed/data_dev.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1825775 (1.7M) [text/plain]\n",
            "Saving to: ‘data_dev.json’\n",
            "\n",
            "data_dev.json       100%[===================>]   1.74M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2021-05-09 21:48:38 (23.8 MB/s) - ‘data_dev.json’ saved [1825775/1825775]\n",
            "\n",
            "--2021-05-09 21:48:38--  https://raw.githubusercontent.com/adamnpeace/nlp-project/model-testing-bertqg/data/preprocessed/data_train.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7332522 (7.0M) [text/plain]\n",
            "Saving to: ‘data_train.json’\n",
            "\n",
            "data_train.json     100%[===================>]   6.99M  46.5MB/s    in 0.2s    \n",
            "\n",
            "2021-05-09 21:48:38 (46.5 MB/s) - ‘data_train.json’ saved [7332522/7332522]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ea63d53-b75d-436a-ba36-8b65d51c779d"
      },
      "source": [
        "bert_model = 'bert-large-uncased'\n",
        "model_path = Path('./models')\n",
        "data_path = Path('.')\n",
        "bert_path = model_path / bert_model"
      ],
      "id": "0ea63d53-b75d-436a-ba36-8b65d51c779d",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "358d7f24-da73-4866-be57-02a461aa922c"
      },
      "source": [
        "if not (model_path / bert_model / 'config.json').is_file():\n",
        "    BertModel.from_pretrained(bert_model).save_pretrained(model_path / bert_model)"
      ],
      "id": "358d7f24-da73-4866-be57-02a461aa922c",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "610d0ea5-84b9-4b23-96cf-ecf9694387f2"
      },
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, n_h_enc, n_h_dec, n_h_attention):\n",
        "        super().__init__()\n",
        "        self.attn = nn.Linear(n_h_enc + n_h_dec, n_h_attention)\n",
        "        self.v = nn.Parameter(torch.rand(n_h_attention), requires_grad=True)\n",
        "        \n",
        "    def forward(self, key, queries):\n",
        "        batch_size, src_len = queries.shape[:2]\n",
        "        \n",
        "        key = key.unsqueeze(1).repeat(1, src_len, 1)\n",
        "        \n",
        "        energy = torch.tanh(self.attn(torch.cat([key, queries], dim=2)))\n",
        "        \n",
        "        v = self.v.repeat(batch_size, 1).unsqueeze(2)\n",
        "        \n",
        "        attn = torch.bmm(energy, v).squeeze(2)\n",
        "        \n",
        "        return F.softmax(attn, dim=1)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, out_dims, emb_dims, n_h_enc, n_h_dec, n_layers, dropout, attn):\n",
        "        super().__init__()\n",
        "        self.out_dims = out_dims\n",
        "        self.emb_dims = emb_dims\n",
        "        self.n_h_enc = n_h_enc\n",
        "        self.n_h_dec = n_h_dec\n",
        "        self.n_layers = n_layers\n",
        "        self.attn = attn\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.embedding = nn.Embedding(out_dims, emb_dims)\n",
        "        \n",
        "        self.rnn = nn.GRU(emb_dims, n_h_dec, batch_first=True, num_layers=n_layers, dropout=dropout)\n",
        "\n",
        "        self.out_dense = nn.Linear(n_h_enc + n_h_dec, out_dims)\n",
        "        \n",
        "    def forward(self, src, queries, hidden):\n",
        "        src = src.unsqueeze(1)\n",
        "        embedded = self.embedding(src)\n",
        "        embedded = self.dropout(embedded)\n",
        "        \n",
        "        out, hidden = self.rnn(embedded, hidden)\n",
        "        out = out.squeeze()\n",
        "        \n",
        "        a = self.attn(out, queries)\n",
        "        a = a.unsqueeze(1)\n",
        "        weighted = torch.bmm(a, queries)\n",
        "        \n",
        "        weighted = weighted.squeeze(1)\n",
        "        \n",
        "        out = self.out_dense(torch.cat([out, weighted], dim=1))\n",
        "        \n",
        "        return out, hidden\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, encoder_trained):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.encoder_trained = encoder_trained\n",
        "        \n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "        input_ids, token_ids, attn_mask = src\n",
        "        \n",
        "        if self.encoder_trained:\n",
        "            bert_hs = self.encoder(input_ids, token_type_ids=token_ids, attention_mask=attn_mask)\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                bert_hs = self.encoder(input_ids, token_type_ids=token_ids, attention_mask=attn_mask)\n",
        "        \n",
        "        bert_encodings = bert_hs[0]\n",
        "        \n",
        "        batch_size, max_len = trg.shape[:2]\n",
        "        \n",
        "        trg_vocab_size = self.decoder.out_dims\n",
        "        \n",
        "        outputs = torch.zeros(batch_size, max_len, trg_vocab_size).to(device)\n",
        "        \n",
        "        out = trg[:, 0]\n",
        "        \n",
        "        hidden = torch.zeros(self.decoder.n_layers, out.shape[0], self.decoder.n_h_dec).to(device)\n",
        "        \n",
        "        for t in range(1, max_len):\n",
        "            out, hidden = self.decoder(out, bert_encodings, hidden)\n",
        "            outputs[:, t] = out\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            out = (trg[:, t] if teacher_force else out.max(1)[1])\n",
        "        \n",
        "        return outputs"
      ],
      "id": "610d0ea5-84b9-4b23-96cf-ecf9694387f2",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30253a22-4652-4a6c-b771-c7ff85dee587"
      },
      "source": [
        "# redo below\n",
        "def enable_reproducibility(seed=69):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "\n",
        "def no_grad(model):\n",
        "    for p in model.parameters():\n",
        "        p.requires_grad = False\n",
        "    return model\n",
        "\n",
        "def no_trainable_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def no_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters())\n",
        "\n",
        "def model_size(model):\n",
        "    return sum(p.element_size() * p.nelement() for p in model.parameters())\n",
        "\n",
        "def save_checkpoint(name, epoch, model, optimizer, valid_loss, train_loss):\n",
        "    torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'valid_loss': valid_loss,\n",
        "            'train_loss': train_loss,\n",
        "            }, name)\n",
        "\n",
        "def load_checkpoint(filename):\n",
        "    checkpoint = torch.load(filename)\n",
        "    return checkpoint['epoch'], checkpoint['model_state_dict'],\\\n",
        "           checkpoint['optimizer_state_dict'], checkpoint['valid_loss'], checkpoint['train_loss']\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_secs = end_time - start_time\n",
        "    elapsed_mins = elapsed_secs / 60\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "id": "30253a22-4652-4a6c-b771-c7ff85dee587",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b55798b4-d551-443a-89c8-8c241c3ecaef"
      },
      "source": [
        "pw_criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "\n",
        "def train(model, dataloader, optimizer, criterion, clip):\n",
        "    log = logging.getLogger(__name__)\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    start = time.time()\n",
        "    for i, (input_, output_) in tqdm(enumerate(dataloader), :\n",
        "\n",
        "        input_data, input_length = input_\n",
        "        output_data, output_length = output_\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        prediction = model([x.to(device) for x in input_data],  output_data.to(device))\n",
        "\n",
        "        trg_sent_len = prediction.size(1)\n",
        "\n",
        "        prediction = prediction[:, 1:].contiguous().view(-1, prediction.shape[-1])\n",
        "        output_data = output_data[:, 1:].contiguous().view(-1)  # Find a way to avoid calling contiguous\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pw_loss = pw_criterion(prediction,  output_data.to(device))\n",
        "\n",
        "        loss = criterion(prediction,  output_data.to(device))\n",
        "\n",
        "        # reshape to [trg sent len - 1, batch size]\n",
        "        loss = loss.view(-1, trg_sent_len - 1)\n",
        "        loss = loss.sum(1)\n",
        "        loss = loss.mean(0)\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.decoder.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        if i % int(len(dataloader) * 0.1) == int(len(dataloader) * 0.1) - 1:\n",
        "            log.info(\n",
        "                f'Batch {i} Sentence loss {loss.item()} Word loss {pw_loss.item()}   Time: {epoch_time(start, time.time())}')\n",
        "            start = time.time()\n",
        "\n",
        "        epoch_loss += pw_loss.item()\n",
        "\n",
        "    return epoch_loss / len(dataloader)"
      ],
      "id": "b55798b4-d551-443a-89c8-8c241c3ecaef",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c51e0d74-7cb0-4334-85fc-676ab4d4212c"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(bert_model)\n",
        "\n",
        "def bleu_score(prediction, ground_truth):\n",
        "    prediction = prediction.max(2)[1]\n",
        "    acc_bleu = 0\n",
        "\n",
        "    for x, y in zip(ground_truth, prediction):\n",
        "        x = tokenizer.convert_ids_to_tokens(x.tolist())\n",
        "        y = tokenizer.convert_ids_to_tokens(y.tolist())\n",
        "        idx1 = x.index('[PAD]') if '[PAD]' in x else len(x)\n",
        "        idx2 = y.index('[SEP]') if '[SEP]' in y else len(y)\n",
        "\n",
        "        acc_bleu += bleu([x[1:idx1 - 1]], y[1:idx2 - 1], smoothing_function=SmoothingFunction().method4)\n",
        "    return acc_bleu / prediction.size(0)\n",
        "\n",
        "def eval(model, dataloader, criterion):\n",
        "    log = logging.getLogger(__name__)\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_bleu = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for i, (input_, output_) in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
        "\n",
        "            input_data, input_length = input_\n",
        "            output_data, output_length = output_\n",
        "\n",
        "            prediction = model([x.to(device) for x in input_data], output_data.to(device), 0)  # turn off teacher forcing\n",
        "\n",
        "            sample_t = tokenizer.convert_ids_to_tokens(output_data[0].tolist())\n",
        "            sample_p = tokenizer.convert_ids_to_tokens(prediction[0].max(1)[1].tolist())\n",
        "            idx1 = sample_t.index('[PAD]') if '[PAD]' in sample_t else len(sample_t)\n",
        "            idx2 = sample_p.index('[SEP]') if '[SEP]' in sample_p else len(sample_p)\n",
        "\n",
        "            bleu = bleu_score(prediction, output_data.to(device))\n",
        "\n",
        "            trg_sent_len = prediction.size(1)\n",
        "            # trg = [trg sent len, batch size]\n",
        "            # output = [trg sent len, batch size, output dim]\n",
        "\n",
        "            prediction = prediction[:, 1:].contiguous().view(-1, prediction.shape[-1])\n",
        "            output_data = output_data[:, 1:].contiguous().view(-1)  # Find a way to avoid calling contiguous\n",
        "\n",
        "            # trg = [(trg sent len - 1) * batch size]\n",
        "            # output = [(trg sent len - 1) * batch size, output dim]\n",
        "\n",
        "            pw_loss = pw_criterion(prediction, output_data.to(device))\n",
        "\n",
        "            loss = criterion(prediction, output_data.to(device))\n",
        "            loss = loss.view(-1, trg_sent_len - 1)\n",
        "            loss = loss.sum(1)\n",
        "            loss = loss.mean(0)\n",
        "\n",
        "            if i % int(len(dataloader) * 0.1) == int(len(dataloader) * 0.1) - 1:\n",
        "                log.info(f'Batch {i} Sentence loss: {loss.item()} Word loss: {pw_loss.item()} BLEU score: {bleu}\\n'\n",
        "                         f'Target {sample_t[1:idx1-1]}\\n'\n",
        "                         f'Prediction {sample_p[1:idx2-1]}\\n\\n')\n",
        "\n",
        "            epoch_loss += pw_loss.item()\n",
        "            epoch_bleu += bleu\n",
        "\n",
        "        return epoch_loss / len(dataloader), epoch_bleu / len(dataloader)"
      ],
      "id": "c51e0d74-7cb0-4334-85fc-676ab4d4212c",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a27734d-bc5d-4a6a-ae53-474908486b69"
      },
      "source": [
        "LENGTH = 512"
      ],
      "id": "1a27734d-bc5d-4a6a-ae53-474908486b69",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "5f214c24-992a-45e9-9d03-fbbb9bf22722"
      },
      "source": [
        "class BertDataset(Dataset):\n",
        "    def __init__(self, json_path, bert_model):\n",
        "        all_data = json.load(open(json_path, 'r'))\n",
        "        input, output = self._extract_data(all_data)\n",
        "        self.data = self._tokenize_data(input, output, bert_model)\n",
        "\n",
        "    def _extract_data(self, all_data):\n",
        "        input, output = [], []\n",
        "        for data in all_data:\n",
        "            input.append((data['passages'], data['responses']))\n",
        "            output.append(data['clues'])\n",
        "        return input, output\n",
        "\n",
        "    def _tokenize_data(self, input, output, bert_model):\n",
        "        tokenizer = BertTokenizer.from_pretrained(bert_model)\n",
        "        \n",
        "        data = tokenizer.batch_encode_plus(input, pad_to_max_length=True, return_tensors='pt')\n",
        "        out_dict = tokenizer.batch_encode_plus(output, pad_to_max_length=True, return_tensors='pt')\n",
        "        \n",
        "        data['output_ids'] = out_dict['input_ids']\n",
        "        data['output_len'] = out_dict['attention_mask'].sum(dim=1)\n",
        "        data['input_len'] = data['attention_mask'].sum(dim=1)\n",
        "        \n",
        "        idx = (data['input_len'] <= LENGTH)\n",
        "        in_m = max(data['input_len'][idx])\n",
        "        out_m = max(data['output_len'][idx])\n",
        "        \n",
        "        data['input_ids'] = data['input_ids'][idx, :in_m]\n",
        "        data['attention_mask'] = data['attention_mask'][idx, :in_m]\n",
        "        data['token_type_ids'] = data['token_type_ids'][idx, :in_m]\n",
        "        data['input_len'] = data['input_len'][idx]\n",
        "        \n",
        "        data['output_ids'] = data['output_ids'][idx, :out_m]\n",
        "        data['output_len'] = data['output_len'][idx]\n",
        "        \n",
        "        return data\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.data['input_ids'].shape[0]\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return (((self.data['input_ids'][idx],\n",
        "                self.data['attention_mask'][idx],\n",
        "                self.data['token_type_ids'][idx]),\n",
        "                self.data['input_len'][idx]),\n",
        "                (self.data['output_ids'][idx],\n",
        "                self.data['output_len'][idx])\n",
        "                )"
      ],
      "id": "5f214c24-992a-45e9-9d03-fbbb9bf22722",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6c1c264-e140-4367-8e46-7566f045309e",
        "outputId": "7eb30c96-4107-4294-8bb3-5da0520fe9cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_set = BertDataset('data_train.json', bert_model)\n",
        "dev_set = BertDataset('data_dev.json', bert_model)"
      ],
      "id": "d6c1c264-e140-4367-8e46-7566f045309e",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1435 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7a88c22-675d-4246-8c4c-0341ca7a0fd0"
      },
      "source": [
        "class HP:\n",
        "    def __init__(self):\n",
        "        self.num_workers = 0\n",
        "        self.pin_memory = False\n",
        "        self.batch_size = 4\n",
        "        self.weight_decay = 0.001\n",
        "        self.lr = 0.05\n",
        "        self.momentum = 0.9\n",
        "        self.decoder_hidden_size = 512\n",
        "        self.decoder_input_size = 512\n",
        "        self.attention_hidden_size = 512\n",
        "        self.n_layers = 1\n",
        "        self.clip = 1\n",
        "        self.dropout = 1\n",
        "        self.n_epochs = 4\n",
        "        self.mb = 32\n",
        "        self.checkpoint = None\n",
        "        self.encoder_trained = False\n",
        "        \n",
        "        conf_file = json.load(open((bert_path / 'config.json'), 'r'))\n",
        "        self.bert_hidden_size = conf_file['hidden_size']\n",
        "        self.bert_vocab_size = conf_file['vocab_size']\n",
        "        \n",
        "        \n",
        "hp = HP()"
      ],
      "id": "a7a88c22-675d-4246-8c4c-0341ca7a0fd0",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efa510eb-1da8-4aa9-830c-1e6193dd5e10"
      },
      "source": [
        "train_loader = DataLoader(train_set, batch_size=hp.batch_size, shuffle=True,\n",
        "                          num_workers=hp.num_workers, pin_memory=hp.pin_memory\n",
        "                         )\n",
        "dev_loader = DataLoader(dev_set, batch_size=hp.batch_size, shuffle=True,\n",
        "                        num_workers=hp.num_workers, pin_memory=hp.pin_memory\n",
        "                       )"
      ],
      "id": "efa510eb-1da8-4aa9-830c-1e6193dd5e10",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd5dee48-3a8b-4509-a59b-b8a513fed6f0"
      },
      "source": [
        "attn = Attention(hp.bert_hidden_size, hp.decoder_hidden_size, hp.attention_hidden_size)\n",
        "decoder = Decoder(hp.bert_vocab_size, hp.decoder_input_size, hp.bert_hidden_size,\n",
        "                  hp.decoder_hidden_size, hp.n_layers, hp.dropout, attn)\n",
        "encoder = BertModel.from_pretrained(bert_path)"
      ],
      "id": "bd5dee48-3a8b-4509-a59b-b8a513fed6f0",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6a1144c-86cd-47b7-8478-cbb0f73b9056"
      },
      "source": [
        "model = Seq2Seq(encoder, decoder, hp.encoder_trained)"
      ],
      "id": "f6a1144c-86cd-47b7-8478-cbb0f73b9056",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abd9f8ac-f0b8-4be7-8be9-11609e236cff"
      },
      "source": [
        "optimizer = optim.SGD(decoder.parameters(), weight_decay=hp.weight_decay, lr=hp.lr, momentum=hp.momentum)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0, reduction='none')"
      ],
      "id": "abd9f8ac-f0b8-4be7-8be9-11609e236cff",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "a6632ab1-3b24-4b25-ac15-61f45ec4c927"
      },
      "source": [
        "model.to(device);"
      ],
      "id": "a6632ab1-3b24-4b25-ac15-61f45ec4c927",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16ff6b7a-e7b1-4739-82ac-038af79a850b"
      },
      "source": [
        "train_losses, dev_losses = [], []"
      ],
      "id": "16ff6b7a-e7b1-4739-82ac-038af79a850b",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73b679d3-4e0b-424c-818d-d337f89b82dc"
      },
      "source": [
        "for epoch in range(hp.n_epochs):\n",
        "    train_loss = train(model, train_loader, optimizer, criterion, hp.clip)\n",
        "    dev_loss, bleu_score = eval(model, dev_loader, criterion)\n",
        "    \n",
        "    train_losses.append(train_loss)\n",
        "    dev_losses.append(dev_loss)"
      ],
      "id": "73b679d3-4e0b-424c-818d-d337f89b82dc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da4edb83-8521-4484-ad26-cf44cff656c5"
      },
      "source": [
        "if checkpoint is not None:\n",
        "    last_epoch, model_dict, optim_dict, valid_loss_list, train_loss_list = load_checkpoint(checkpoint)\n",
        "    last_epoch += 1\n",
        "    model.load_state_dict(model_dict)\n",
        "    \n",
        "    best_valid_loss = min(valid_loss_list)\n",
        "    \n",
        "    optimizer.load_state_dict(optim_dict)\n",
        "    \n",
        "    for state in optimizer.state.values():\n",
        "        for k, v in state.items():"
      ],
      "id": "da4edb83-8521-4484-ad26-cf44cff656c5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfc68fe9-c034-457f-bb97-4afe7b60f730"
      },
      "source": [
        ""
      ],
      "id": "bfc68fe9-c034-457f-bb97-4afe7b60f730",
      "execution_count": null,
      "outputs": []
    }
  ]
}