{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "25529b09-0de3-43a5-a398-c2424a2b8334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle, time, random, logging, json, gc, warnings\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import AdamW, BertConfig, BertTokenizer\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import EncoderDecoderModel\n",
    "from transformers import BertModel\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import spacy\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dd9406b-bd64-4435-98c1-d1af433684ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8840c32c-6845-4206-a8ba-6a688e9f1abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0ea63d53-b75d-436a-ba36-8b65d51c779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = 'bert-large-uncased'\n",
    "model_path = Path('./models')\n",
    "data_path = Path('../data')\n",
    "bert_path = model_path / bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "358d7f24-da73-4866-be57-02a461aa922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (model_path / bert_model / 'config.json').is_file():\n",
    "    BertModel.from_pretrained(bert_model).save_pretrained(model_path / bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "610d0ea5-84b9-4b23-96cf-ecf9694387f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, n_h_enc, n_h_dec, n_h_attention):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(n_h_enc + n_h_dec, n_h_attention)\n",
    "        self.v = nn.Parameter(torch.rand(n_h_attention), requires_grad=True)\n",
    "        \n",
    "    def forward(self, key, queries):\n",
    "        batch_size, src_len = queries.shape\n",
    "        \n",
    "        key = key.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        \n",
    "        energy = torch.tanh(self.attn(torch.cat([key, queries], dim=2)))\n",
    "        \n",
    "        v = self.v.repeat(batch_size, 1).unsqueeze(2)\n",
    "        \n",
    "        attn = torch.bmm(energy, v).squeeze(2)\n",
    "        \n",
    "        return F.softmax(attn, dim=1)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, out_dims, emb_dims, n_h_enc, n_h_dec, n_layers, dropout, attn):\n",
    "        super().__init__()\n",
    "        self.out_dims = out_dims\n",
    "        self.emb_dims = emb_dims\n",
    "        self.n_h_enc = n_h_enc\n",
    "        self.n_h_dec = n_h_dec\n",
    "        self.n_layers = n_layers\n",
    "        self.attn = attn\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.embedding = nn.Embedding(out_dims, emb_dims)\n",
    "        \n",
    "        self.rnn = nn.GRU(emb_dims, n_h_dec, batch_first=True, num_layers=n_layers, dropout=dropout)\n",
    "        \n",
    "    def forward(self, src, queries, hidden):\n",
    "        src = src.unsqueeze(1)\n",
    "        embedded = self.embedding(src)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        out, hidden = self.rnn(embedded, hidden)\n",
    "        out = out.squeeze()\n",
    "        \n",
    "        a = self.attn(out, queries)\n",
    "        a = a.unsqueeze(1)\n",
    "        weighted = torch.bmm(a, queries)\n",
    "        \n",
    "        weighted = weighted.squeeze(1)\n",
    "        \n",
    "        out = self.out(torch.cat([out, weighted], dim=1))\n",
    "        \n",
    "        return out, hidden\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, encoder_trained):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.encoder_trained = encoder_trained\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        input_ids, token_ids, attn_mask = src\n",
    "        \n",
    "        if self.encoder_trained:\n",
    "            bert_hs = self.encoder(input_ids, token_type_ids=token_ids, attention_mask=attn_mask)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                bert_hs = self.encoder(input_ids, token_type_ids=token_ids, attention_mask=attn_mask)\n",
    "        \n",
    "        bert_encodings = bert_hs[0]\n",
    "        \n",
    "        batch_size, max_len = trg.shape\n",
    "        \n",
    "        trg_vocab_size = self.decoder.out_dims\n",
    "        \n",
    "        outputs = torch.zeros(batch_size, max_len, trg_vocab_size).to(device)\n",
    "        \n",
    "        out = trg[:, 0]\n",
    "        \n",
    "        hidden = torch.zeros(self.decoder.n_layers, out.shape[0], self.decoder.n_h_dec).to(device)\n",
    "        \n",
    "        for t in range(1, max_len):\n",
    "            out, hidden = self.decoder(out, bert_encodings, hidden)\n",
    "            outputs[:, t] = out\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            out = (trg[:, t] if teacher_force else output.max(1)[1])\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "30253a22-4652-4a6c-b771-c7ff85dee587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redo below\n",
    "def enable_reproducibility(seed=69):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "\n",
    "def no_grad(model):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = False\n",
    "    return model\n",
    "\n",
    "def no_trainable_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def no_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "def model_size(model):\n",
    "    return sum(p.element_size() * p.nelement() for p in model.parameters())\n",
    "\n",
    "def save_checkpoint(name, epoch, model, optimizer, valid_loss, train_loss):\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'valid_loss': valid_loss,\n",
    "            'train_loss': train_loss,\n",
    "            }, name)\n",
    "\n",
    "def load_checkpoint(filename):\n",
    "    checkpoint = torch.load(filename)\n",
    "    return checkpoint['epoch'], checkpoint['model_state_dict'],\\\n",
    "           checkpoint['optimizer_state_dict'], checkpoint['valid_loss'], checkpoint['train_loss']\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_secs = end_time - start_time\n",
    "    elapsed_mins = elapsed_secs / 60\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b55798b4-d551-443a-89c8-8c241c3ecaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pw_criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "def train(model, dataloader, optimizer, criterion, clip):\n",
    "    log = logging.getLogger(__name__)\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    start = time.time()\n",
    "    for i, (input_, output_) in enumerate(dataloader):\n",
    "\n",
    "        input_data, input_length = input_\n",
    "        output_data, output_length = output_\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        prediction = model([x.to(device) for x in input_data],  output_data.to(device))\n",
    "\n",
    "        trg_sent_len = prediction.size(1)\n",
    "\n",
    "        prediction = prediction[:, 1:].contiguous().view(-1, prediction.shape[-1])\n",
    "        output_data = output_data[:, 1:].contiguous().view(-1)  # Find a way to avoid calling contiguous\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pw_loss = pw_criterion(prediction,  output_data.to(device))\n",
    "\n",
    "        loss = criterion(prediction,  output_data.to(device))\n",
    "\n",
    "        # reshape to [trg sent len - 1, batch size]\n",
    "        loss = loss.view(-1, trg_sent_len - 1)\n",
    "        loss = loss.sum(1)\n",
    "        loss = loss.mean(0)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.decoder.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % int(len(dataloader) * 0.1) == int(len(dataloader) * 0.1) - 1:\n",
    "            log.info(\n",
    "                f'Batch {i} Sentence loss {loss.item()} Word loss {pw_loss.item()}   Time: {epoch_time(start, time.time())}')\n",
    "            start = time.time()\n",
    "\n",
    "        epoch_loss += pw_loss.item()\n",
    "\n",
    "    return epoch_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c51e0d74-7cb0-4334-85fc-676ab4d4212c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(bert_model)\n",
    "\n",
    "def bleu_score(prediction, ground_truth):\n",
    "    prediction = prediction.max(2)[1]\n",
    "    acc_bleu = 0\n",
    "\n",
    "    for x, y in zip(ground_truth, prediction):\n",
    "        x = tokenizer.convert_ids_to_tokens(x.tolist())\n",
    "        y = tokenizer.convert_ids_to_tokens(y.tolist())\n",
    "        idx1 = x.index('[PAD]') if '[PAD]' in x else len(x)\n",
    "        idx2 = y.index('[SEP]') if '[SEP]' in y else len(y)\n",
    "\n",
    "        acc_bleu += bleu([x[1:idx1 - 1]], y[1:idx2 - 1], smoothing_function=SmoothingFunction().method4)\n",
    "    return acc_bleu / prediction.size(0)\n",
    "\n",
    "def eval(model, dataloader, criterion):\n",
    "    log = logging.getLogger(__name__)\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_bleu = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i, (input_, output_) in enumerate(dataloader):\n",
    "\n",
    "            input_data, input_length = input_\n",
    "            output_data, output_length = output_\n",
    "\n",
    "            prediction = model([x.to(device) for x in input_data], output_data.to(device), 0)  # turn off teacher forcing\n",
    "\n",
    "            sample_t = tokenizer.convert_ids_to_tokens(output_data[0].tolist())\n",
    "            sample_p = tokenizer.convert_ids_to_tokens(prediction[0].max(1)[1].tolist())\n",
    "            idx1 = sample_t.index('[PAD]') if '[PAD]' in sample_t else len(sample_t)\n",
    "            idx2 = sample_p.index('[SEP]') if '[SEP]' in sample_p else len(sample_p)\n",
    "\n",
    "            bleu = bleu_score(prediction, output_data.to(device))\n",
    "\n",
    "            trg_sent_len = prediction.size(1)\n",
    "            # trg = [trg sent len, batch size]\n",
    "            # output = [trg sent len, batch size, output dim]\n",
    "\n",
    "            prediction = prediction[:, 1:].contiguous().view(-1, prediction.shape[-1])\n",
    "            output_data = output_data[:, 1:].contiguous().view(-1)  # Find a way to avoid calling contiguous\n",
    "\n",
    "            # trg = [(trg sent len - 1) * batch size]\n",
    "            # output = [(trg sent len - 1) * batch size, output dim]\n",
    "\n",
    "            pw_loss = pw_criterion(prediction, output_data.to(device))\n",
    "\n",
    "            loss = criterion(prediction, output_data.to(device))\n",
    "            loss = loss.view(-1, trg_sent_len - 1)\n",
    "            loss = loss.sum(1)\n",
    "            loss = loss.mean(0)\n",
    "\n",
    "            if i % int(len(dataloader) * 0.1) == int(len(dataloader) * 0.1) - 1:\n",
    "                log.info(f'Batch {i} Sentence loss: {loss.item()} Word loss: {pw_loss.item()} BLEU score: {bleu}\\n'\n",
    "                         f'Target {sample_t[1:idx1-1]}\\n'\n",
    "                         f'Prediction {sample_p[1:idx2-1]}\\n\\n')\n",
    "\n",
    "            epoch_loss += pw_loss.item()\n",
    "            epoch_bleu += bleu\n",
    "\n",
    "        return epoch_loss / len(dataloader), epoch_bleu / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1a27734d-bc5d-4a6a-ae53-474908486b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5f214c24-992a-45e9-9d03-fbbb9bf22722",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BertDataset(Dataset):\n",
    "    def __init__(self, json_path, bert_model):\n",
    "        all_data = json.load(open(json_path, 'r'))\n",
    "        input, output = self._extract_data(all_data)\n",
    "        self.data = self._tokenize_data(input, output, bert_model)\n",
    "\n",
    "    def _extract_data(self, all_data):\n",
    "        input, output = [], []\n",
    "        for data in all_data:\n",
    "            input.append((data['passages'], data['responses']))\n",
    "            output.append(data['clues'])\n",
    "        return input, output\n",
    "\n",
    "    def _tokenize_data(self, input, output, bert_model):\n",
    "        tokenizer = BertTokenizer.from_pretrained(bert_model)\n",
    "        \n",
    "        data = tokenizer.batch_encode_plus(input, pad_to_max_length=True, return_tensors='pt')\n",
    "        out_dict = tokenizer.batch_encode_plus(output, pad_to_max_length=True, return_tensors='pt')\n",
    "        \n",
    "        data['output_ids'] = out_dict['input_ids']\n",
    "        data['output_len'] = out_dict['attention_mask'].sum(dim=1)\n",
    "        data['input_len'] = data['attention_mask'].sum(dim=1)\n",
    "        \n",
    "        idx = (data['input_len'] <= LENGTH)\n",
    "        in_m = max(data['input_len'][idx])\n",
    "        out_m = max(data['output_len'][idx])\n",
    "        \n",
    "        data['input_ids'] = data['input_ids'][idx, :in_m]\n",
    "        data['attention_mask'] = data['attention_mask'][idx, :in_m]\n",
    "        data['token_type_ids'] = data['token_type_ids'][idx, :in_m]\n",
    "        data['input_len'] = data['input_len'][idx]\n",
    "        \n",
    "        data['output_ids'] = data['output_ids'][idx, :out_m]\n",
    "        data['output_len'] = data['output_len'][idx]\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data['input_ids'].shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (((self.data['input_ids'][idx],\n",
    "                self.data['attention_mask'][idx],\n",
    "                self.data['token_type_ids'][idx]),\n",
    "                self.data['input_len'][idx]),\n",
    "                (self.data['output_ids'][idx],\n",
    "                self.data['output_len'][idx])\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d6c1c264-e140-4367-8e46-7566f045309e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e17ee286f6554ff2b5646ef2c53cd516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b99b67916e2341318203820427c0f08a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "039c006c8b8c4151a6af6d2505122bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1241 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "train_set = BertDataset('data_train.json', bert_model)\n",
    "dev_set = BertDataset('data_dev.json', bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a7a88c22-675d-4246-8c4c-0341ca7a0fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HP:\n",
    "    def __init__(self):\n",
    "        self.num_workers = 0\n",
    "        self.pin_memory = False\n",
    "        self.batch_size = 4\n",
    "        self.weight_decay = 0.001\n",
    "        self.lr = 0.05\n",
    "        self.momentum = 0.9\n",
    "        self.decoder_hidden_size = 512\n",
    "        self.decoder_input_size = 512\n",
    "        self.attention_hidden_size = 512\n",
    "        self.n_layers = 1\n",
    "        self.clip = 1\n",
    "        self.dropout = 1\n",
    "        self.n_epochs = 4\n",
    "        self.mb = 32\n",
    "        self.checkpoint = None\n",
    "        self.encoder_trained = False\n",
    "        \n",
    "        conf_file = json.load(open((bert_path / 'config.json'), 'r'))\n",
    "        self.bert_hidden_size = conf_file['hidden_size']\n",
    "        self.bert_vocab_size = conf_file['vocab_size']\n",
    "        \n",
    "        \n",
    "hp = HP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "efa510eb-1da8-4aa9-830c-1e6193dd5e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=hp.num_workers, pin_memory=hp.pin_memory\n",
    "                         )\n",
    "dev_loader = DataLoader(dev_set, batch_size=hp.batch_size, shuffle=True,\n",
    "                        num_workers=hp.num_workers, pin_memory=hp.pin_memory\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "bd5dee48-3a8b-4509-a59b-b8a513fed6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = Attention(hp.bert_hidden_size, hp.decoder_hidden_size, hp.attention_hidden_size)\n",
    "decoder = Decoder(hp.bert_vocab_size, hp.decoder_input_size, hp.bert_hidden_size,\n",
    "                  hp.decoder_hidden_size, hp.n_layers, hp.dropout, attn)\n",
    "encoder = BertModel.from_pretrained(bert_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f6a1144c-86cd-47b7-8478-cbb0f73b9056",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(encoder, decoder, hp.encoder_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "abd9f8ac-f0b8-4be7-8be9-11609e236cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(decoder.parameters(), weight_decay=hp.weight_decay, lr=hp.lr, momentum=hp.momentum)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a6632ab1-3b24-4b25-ac15-61f45ec4c927",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 9.78 GiB total capacity; 4.12 GiB already allocated; 11.12 MiB free; 4.15 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-146-61af721bb882>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/dev/.pyvenvs/qa/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m~/dev/.pyvenvs/qa/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/.pyvenvs/qa/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/.pyvenvs/qa/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_weights_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;31m# Flattens params (on CUDA)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/.pyvenvs/qa/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mflatten_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    174\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cudnn_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m                         self.batch_first, bool(self.bidirectional))  # type: ignore\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 9.78 GiB total capacity; 4.12 GiB already allocated; 11.12 MiB free; 4.15 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ff6b7a-e7b1-4739-82ac-038af79a850b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, dev_losses = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b679d3-4e0b-424c-818d-d337f89b82dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(hp.n_epochs):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, hp.clip)\n",
    "    dev_loss, bleu_score = eval(model, dev_loader, criterion)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    dev_losses.append(dev_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "33c78410-c4cd-4985-8beb-14497cd978f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May  9 22:30:59 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 3080    On   | 00000000:07:00.0 Off |                  N/A |\n",
      "|  0%   49C    P2    92W / 320W |   7116MiB / 10015MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1002      G   /usr/lib/xorg/Xorg                  9MiB |\n",
      "|    0   N/A  N/A      1226      G   /usr/bin/gnome-shell                6MiB |\n",
      "|    0   N/A  N/A      7252      C   ...pyvenvs/qa-old/bin/python     4073MiB |\n",
      "|    0   N/A  N/A      9037      C   ...ev/.pyvenvs/qa/bin/python     3023MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4edb83-8521-4484-ad26-cf44cff656c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if checkpoint is not None:\n",
    "    last_epoch, model_dict, optim_dict, valid_loss_list, train_loss_list = load_checkpoint(checkpoint)\n",
    "    last_epoch += 1\n",
    "    model.load_state_dict(model_dict)\n",
    "    \n",
    "    best_valid_loss = min(valid_loss_list)\n",
    "    \n",
    "    optimizer.load_state_dict(optim_dict)\n",
    "    \n",
    "    for state in optimizer.state.values():\n",
    "        for k, v in state.items():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc68fe9-c034-457f-bb97-4afe7b60f730",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QA-nlp",
   "language": "python",
   "name": "qa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
