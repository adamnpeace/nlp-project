{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73e1154b-9427-4b22-89bd-5f1bacaaec82",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "niSDQPa-GPyt",
    "outputId": "7ac1dbe4-1f6a-48ac-8f49-efaeba60142a"
   },
   "outputs": [],
   "source": [
    "# !nvidia-smi\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# !pip install transformers\n",
    "\n",
    "# !wget -N https://raw.githubusercontent.com/adamnpeace/nlp-project/model-testing-bertqg/data/preprocessed/data_dev.json\n",
    "# !wget -N https://raw.githubusercontent.com/adamnpeace/nlp-project/model-testing-bertqg/data/preprocessed/data_train.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25529b09-0de3-43a5-a398-c2424a2b8334",
   "metadata": {
    "id": "25529b09-0de3-43a5-a398-c2424a2b8334"
   },
   "outputs": [],
   "source": [
    "import os, pickle, time, random, logging, json, gc, warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import AdamW, BertConfig, BertTokenizer\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import EncoderDecoderModel\n",
    "from transformers import BertModel\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.translate import bleu\n",
    "import spacy\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dd9406b-bd64-4435-98c1-d1af433684ba",
   "metadata": {
    "id": "3dd9406b-bd64-4435-98c1-d1af433684ba"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ea63d53-b75d-436a-ba36-8b65d51c779d",
   "metadata": {
    "id": "0ea63d53-b75d-436a-ba36-8b65d51c779d"
   },
   "outputs": [],
   "source": [
    "model_path = Path('./models')\n",
    "data_path = Path('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358d7f24-da73-4866-be57-02a461aa922c",
   "metadata": {
    "id": "358d7f24-da73-4866-be57-02a461aa922c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7a88c22-675d-4246-8c4c-0341ca7a0fd0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 98,
     "referenced_widgets": [
      "5213099ab0904d56bfa29610408427fb",
      "e04eb9d308d24d37983a110538c724b3",
      "5b25bd5ed8bb40a7bf06ddd6d661865b",
      "42eabbf2c76443cca2621b3af7926637",
      "faf2f83be9d14eb5af9449402951fd0b",
      "30e051d7f5944bed926d8f1a29a903da",
      "dd2ea4ab0ba54d11aaf79ff19cfbe0a6",
      "c3d26e9d73a54b32a48624df61d8ba55",
      "97e85d071a8c48c69993f3d91de06e13",
      "08d0fb82f9aa4b2a8047cfb1fa089908",
      "9187f91691d7486fbd69a1bb90f1fe9e",
      "ba43d4279f8345aa8fa8b6f4442c7aa1",
      "5d46207da0b54f84a1cb7c12cdb04682",
      "d0dcc4e2f8d942b496fd36c544e98db9",
      "1e10eae4f2e44eeaa426ca46da3d76b7",
      "0330c53a614143669eb753cc9d5431b3"
     ]
    },
    "id": "a7a88c22-675d-4246-8c4c-0341ca7a0fd0",
    "outputId": "26729f3a-cc7c-4811-be8f-1d9b7730a41f"
   },
   "outputs": [],
   "source": [
    "class HP:\n",
    "    def __init__(self):\n",
    "        self.num_workers = 0\n",
    "        self.pin_memory = False\n",
    "        self.batch_size = 4\n",
    "        self.weight_decay = 0.001\n",
    "        self.sgd = True\n",
    "        if self.sgd:\n",
    "            self.lr = 0.05\n",
    "            self.momentum = 0.9\n",
    "        else:\n",
    "            self.lr = 0.001\n",
    "            self.momentum = None\n",
    "            \n",
    "        self.decoder_hidden_size = 512\n",
    "        self.decoder_input_size = 512\n",
    "        self.attention_hidden_size = 512\n",
    "        self.max_input_length = 512\n",
    "        self.n_layers = 1\n",
    "        self.clip = 1\n",
    "        self.dropout = 1\n",
    "        self.n_epochs = 4\n",
    "        self.max_epochs = 32\n",
    "        self.patience = 3\n",
    "        self.mb = 32\n",
    "        self.checkpoint = None\n",
    "        self.encoder_trained = False\n",
    "\n",
    "        self.pw_criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "        self.bert_model = 'bert-large-uncased'\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(self.bert_model)\n",
    "        \n",
    "        self.bert_path = model_path / self.bert_model\n",
    "\n",
    "        if not (model_path / self.bert_model / 'config.json').is_file():\n",
    "            BertModel.from_pretrained(self.bert_model).save_pretrained(model_path / self.bert_model)\n",
    "        conf_file = json.load(open((self.bert_path / 'config.json'), 'r'))\n",
    "        self.bert_hidden_size = conf_file['hidden_size']\n",
    "        self.bert_vocab_size = conf_file['vocab_size']\n",
    "        \n",
    "hp = HP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "610d0ea5-84b9-4b23-96cf-ecf9694387f2",
   "metadata": {
    "id": "610d0ea5-84b9-4b23-96cf-ecf9694387f2"
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, n_h_enc, n_h_dec, n_h_attention):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(n_h_enc + n_h_dec, n_h_attention)\n",
    "        self.v = nn.Parameter(torch.rand(n_h_attention), requires_grad=True)\n",
    "        \n",
    "    def forward(self, key, queries):\n",
    "        batch_size, src_len = queries.shape[:2]\n",
    "        \n",
    "        key = key.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        if key.size(0) != queries.size(0) or key.size(1) != queries.size(1):\n",
    "            print(key.shape, queries.shape)\n",
    "        kitten = torch.cat((key, queries), dim=2)\n",
    "        energy = torch.tanh(self.attn(kitten))\n",
    "        \n",
    "        v = self.v.repeat(batch_size, 1).unsqueeze(2)\n",
    "        \n",
    "        attn = torch.bmm(energy, v).squeeze(2)\n",
    "        \n",
    "        return F.softmax(attn, dim=1)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, out_dims, emb_dims, n_h_enc, n_h_dec, n_layers, dropout, attn):\n",
    "        super().__init__()\n",
    "        self.out_dims = out_dims\n",
    "        self.emb_dims = emb_dims\n",
    "        self.n_h_enc = n_h_enc\n",
    "        self.n_h_dec = n_h_dec\n",
    "        self.n_layers = n_layers\n",
    "        self.attn = attn\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.embedding = nn.Embedding(out_dims, emb_dims)\n",
    "        \n",
    "        self.rnn = nn.GRU(emb_dims, n_h_dec, batch_first=True, num_layers=n_layers, dropout=dropout)\n",
    "\n",
    "        self.out_dense = nn.Linear(n_h_enc + n_h_dec, out_dims)\n",
    "        \n",
    "    def forward(self, src, queries, hidden):\n",
    "        src = src.unsqueeze(1)\n",
    "        embedded = self.embedding(src)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        out, hidden = self.rnn(embedded, hidden)\n",
    "        out = out.squeeze()\n",
    "        \n",
    "        a = self.attn(out, queries)\n",
    "        a = a.unsqueeze(1)\n",
    "        weighted = torch.bmm(a, queries)\n",
    "        \n",
    "        weighted = weighted.squeeze(1)\n",
    "        \n",
    "        out = self.out_dense(torch.cat([out, weighted], dim=1))\n",
    "        \n",
    "        return out, hidden\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, encoder_trained):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.encoder_trained = encoder_trained\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        input_ids, token_ids, attn_mask = src\n",
    "        \n",
    "        if self.encoder_trained:\n",
    "            bert_hs = self.encoder(input_ids, token_type_ids=token_ids, attention_mask=attn_mask)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                bert_hs = self.encoder(input_ids, token_type_ids=token_ids, attention_mask=attn_mask)\n",
    "        \n",
    "        bert_encodings = bert_hs[0]\n",
    "        \n",
    "        batch_size, max_len = trg.shape[:2]\n",
    "        \n",
    "        trg_vocab_size = self.decoder.out_dims\n",
    "        \n",
    "        outputs = torch.zeros(batch_size, max_len, trg_vocab_size).to(device)\n",
    "        \n",
    "        out = trg[:, 0]\n",
    "        \n",
    "        hidden = torch.zeros(self.decoder.n_layers, out.shape[0], self.decoder.n_h_dec).to(device)\n",
    "        \n",
    "        for t in range(1, max_len):\n",
    "            out, hidden = self.decoder(out, bert_encodings, hidden)\n",
    "            outputs[:, t] = out\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            out = (trg[:, t] if teacher_force else out.max(1)[1])\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30253a22-4652-4a6c-b771-c7ff85dee587",
   "metadata": {
    "id": "30253a22-4652-4a6c-b771-c7ff85dee587"
   },
   "outputs": [],
   "source": [
    "# redo below\n",
    "def enable_reproducibility(seed=69):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "\n",
    "def no_grad(model):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = False\n",
    "    return model\n",
    "\n",
    "def no_trainable_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def no_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "def model_size(model):\n",
    "    return sum(p.element_size() * p.nelement() for p in model.parameters())\n",
    "\n",
    "def save_checkpoint(name, epoch, model, optimizer, valid_loss, train_loss):\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'valid_loss': valid_loss,\n",
    "            'train_loss': train_loss,\n",
    "            }, name)\n",
    "\n",
    "def load_checkpoint(filename):\n",
    "    checkpoint = torch.load(filename)\n",
    "    return checkpoint['epoch'], checkpoint['model_state_dict'],\\\n",
    "           checkpoint['optimizer_state_dict'], checkpoint['valid_loss'], checkpoint['train_loss']\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_secs = end_time - start_time\n",
    "    elapsed_mins = elapsed_secs / 60\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b55798b4-d551-443a-89c8-8c241c3ecaef",
   "metadata": {
    "id": "b55798b4-d551-443a-89c8-8c241c3ecaef"
   },
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion, clip):\n",
    "    log = logging.getLogger(__name__)\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    start = time.time()\n",
    "    for i, (input_, output_) in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "\n",
    "        input_data, input_length = input_\n",
    "        output_data, output_length = output_\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        prediction = model([x.to(device) for x in input_data],  output_data.to(device))\n",
    "\n",
    "        trg_sent_len = prediction.size(1)\n",
    "\n",
    "        prediction = prediction[:, 1:].contiguous().view(-1, prediction.shape[-1])\n",
    "        output_data = output_data[:, 1:].contiguous().view(-1)  # Find a way to avoid calling contiguous\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pw_loss = hp.pw_criterion(prediction,  output_data.to(device))\n",
    "\n",
    "        loss = criterion(prediction,  output_data.to(device))\n",
    "\n",
    "        # reshape to [trg sent len - 1, batch size]\n",
    "        loss = loss.view(-1, trg_sent_len - 1)\n",
    "        loss = loss.sum(1)\n",
    "        loss = loss.mean(0)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.decoder.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % int(len(dataloader) * 0.1) == int(len(dataloader) * 0.1) - 1:\n",
    "            print('Batch {}: Sentence Loss: {:.3f}, Word Loss: {:.3f}'\n",
    "                  .format(i, loss.item(), pw_loss.item()))\n",
    "            start = time.time()\n",
    "\n",
    "        epoch_loss += pw_loss.item()\n",
    "\n",
    "    return epoch_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c51e0d74-7cb0-4334-85fc-676ab4d4212c",
   "metadata": {
    "id": "c51e0d74-7cb0-4334-85fc-676ab4d4212c"
   },
   "outputs": [],
   "source": [
    "def bleu_score(prediction, ground_truth):\n",
    "    prediction = prediction.max(2)[1]\n",
    "    acc_bleu = 0\n",
    "\n",
    "    for x, y in zip(ground_truth, prediction):\n",
    "        x = hp.tokenizer.convert_ids_to_tokens(x.tolist())\n",
    "        y = hp.tokenizer.convert_ids_to_tokens(y.tolist())\n",
    "        idx1 = x.index('[PAD]') if '[PAD]' in x else len(x)\n",
    "        idx2 = y.index('[SEP]') if '[SEP]' in y else len(y)\n",
    "\n",
    "        acc_bleu += bleu([x[1:idx1 - 1]], y[1:idx2 - 1], smoothing_function=SmoothingFunction().method4)\n",
    "    return acc_bleu / prediction.size(0)\n",
    "\n",
    "def eval(model, dataloader, criterion):\n",
    "    log = logging.getLogger(__name__)\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_bleu = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i, (input_, output_) in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "\n",
    "            input_data, input_length = input_\n",
    "            output_data, output_length = output_\n",
    "\n",
    "            prediction = model([x.to(device) for x in input_data], output_data.to(device), 0)  # turn off teacher forcing\n",
    "\n",
    "            sample_t = hp.tokenizer.convert_ids_to_tokens(output_data[0].tolist())\n",
    "            sample_p = hp.tokenizer.convert_ids_to_tokens(prediction[0].max(1)[1].tolist())\n",
    "            idx1 = sample_t.index('[PAD]') if '[PAD]' in sample_t else len(sample_t)\n",
    "            idx2 = sample_p.index('[SEP]') if '[SEP]' in sample_p else len(sample_p)\n",
    "\n",
    "            bleu_i = bleu_score(prediction, output_data.to(device))\n",
    "\n",
    "            trg_sent_len = prediction.size(1)\n",
    "            # trg = [trg sent len, batch size]\n",
    "            # output = [trg sent len, batch size, output dim]\n",
    "\n",
    "            prediction = prediction[:, 1:].contiguous().view(-1, prediction.shape[-1])\n",
    "            output_data = output_data[:, 1:].contiguous().view(-1)  # Find a way to avoid calling contiguous\n",
    "\n",
    "            # trg = [(trg sent len - 1) * batch size]\n",
    "            # output = [(trg sent len - 1) * batch size, output dim]\n",
    "\n",
    "            pw_loss = hp.pw_criterion(prediction, output_data.to(device))\n",
    "\n",
    "            loss = criterion(prediction, output_data.to(device))\n",
    "            loss = loss.view(-1, trg_sent_len - 1)\n",
    "            loss = loss.sum(1)\n",
    "            loss = loss.mean(0)\n",
    "\n",
    "            if i % int(len(dataloader) * 0.1) == int(len(dataloader) * 0.1) - 1:\n",
    "                print('Batch {}: Sentence Loss: {:.3f}, Word Loss: {:.3f}, BLEU score {:.4f}'.format(i, loss.item(), pw_loss.item(), bleu_i))\n",
    "            print(\n",
    "                    'Target -> {}\\nPrediction -> {}\\n\\n'.format(\n",
    "                        sample_t[1:idx1-1], sample_p[1:idx2-1]\n",
    "                    ))\n",
    "            \n",
    "            epoch_loss += pw_loss.item()\n",
    "            epoch_bleu += bleu_i\n",
    "\n",
    "        return epoch_loss / len(dataloader), epoch_bleu / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4399f602-8978-428a-aa71-b458e5f763be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf33e34e-b1cd-41e0-81bd-44b8bcedc880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \\\"Super Bowl L\\\"), so that the logo could prominently feature the Arabic numerals 50.\".split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4532fb48-0064-4994-9955-81957beb75b8",
   "metadata": {
    "id": "5f214c24-992a-45e9-9d03-fbbb9bf22722",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BertDataset(Dataset):\n",
    "    def __init__(self, json_path):\n",
    "        all_data = json.load(open(json_path, 'r'))\n",
    "        input, output = self._extract_data(all_data)\n",
    "        self.data = self._tokenize_data(input, output)\n",
    "\n",
    "#     def _extract_data(self, all_data):\n",
    "#         input, output = [], []\n",
    "#         assert 'offset' in all_data[0]\n",
    "#         for data in all_data:\n",
    "            \n",
    "#             input.append((data['passages'], data['responses']))\n",
    "#             output.append(data['clues'])\n",
    "#         input, output = input[:-1], output[:-1]\n",
    "#         return input, output\n",
    "    \n",
    "    def _extract_data(self, all_data):\n",
    "        input, output = [], []\n",
    "        dataset = all_data['data']\n",
    "        \n",
    "        for category_i, category in enumerate(dataset):\n",
    "            for para in category['paragraphs']:\n",
    "                for question in para['qas']:\n",
    "                    input.append((para['context'], question['answers'][0]['text']))\n",
    "                    output.append(question['question'])\n",
    "        return input, output\n",
    "\n",
    "    def _tokenize_data(self, input, output):       \n",
    "        data = hp.tokenizer.batch_encode_plus(input, pad_to_max_length=True, return_tensors='pt')\n",
    "        out_dict = hp.tokenizer.batch_encode_plus(output, pad_to_max_length=True, return_tensors='pt')\n",
    "        \n",
    "        data['output_ids'] = out_dict['input_ids']\n",
    "        data['output_len'] = out_dict['attention_mask'].sum(dim=1)\n",
    "        data['input_len'] = data['attention_mask'].sum(dim=1)\n",
    "        \n",
    "        idx = (data['input_len'] <= hp.max_input_length)\n",
    "        in_m = max(data['input_len'][idx])\n",
    "        out_m = max(data['output_len'][idx])\n",
    "        \n",
    "        data['input_ids'] = data['input_ids'][idx, :in_m]\n",
    "        data['attention_mask'] = data['attention_mask'][idx, :in_m]\n",
    "        data['token_type_ids'] = data['token_type_ids'][idx, :in_m]\n",
    "        data['input_len'] = data['input_len'][idx]\n",
    "        \n",
    "        data['output_ids'] = data['output_ids'][idx, :out_m]\n",
    "        data['output_len'] = data['output_len'][idx]\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data['input_ids'].shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (((self.data['input_ids'][idx],\n",
    "                self.data['attention_mask'][idx],\n",
    "                self.data['token_type_ids'][idx]),\n",
    "                self.data['input_len'][idx]),\n",
    "                (self.data['output_ids'][idx],\n",
    "                self.data['output_len'][idx])\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6c1c264-e140-4367-8e46-7566f045309e",
   "metadata": {
    "id": "d6c1c264-e140-4367-8e46-7566f045309e"
   },
   "outputs": [],
   "source": [
    "# train_set = BertDataset('data_train.json')\n",
    "# dev_set = BertDataset('data_dev.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ddcb87-278b-4569-9896-c7a958afa6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (630 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "train_set = BertDataset(Path('../../nlp/stanford-question-answering-dataset/dev-v1.1.json'))\n",
    "dev_set = BertDataset(Path('../../nlp/stanford-question-answering-dataset/train-v1.1.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a21611b-4cc7-4201-8c67-0456724b3d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_set = BertDataset(Path('../../nlp/stanford-question-answering-dataset/train-v1.1.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa510eb-1da8-4aa9-830c-1e6193dd5e10",
   "metadata": {
    "id": "efa510eb-1da8-4aa9-830c-1e6193dd5e10"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=hp.batch_size, shuffle=True,\n",
    "                          num_workers=hp.num_workers, pin_memory=hp.pin_memory\n",
    "                         )\n",
    "dev_loader = DataLoader(dev_set, batch_size=hp.batch_size, shuffle=True,\n",
    "                        num_workers=hp.num_workers, pin_memory=hp.pin_memory\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5dee48-3a8b-4509-a59b-b8a513fed6f0",
   "metadata": {
    "id": "bd5dee48-3a8b-4509-a59b-b8a513fed6f0"
   },
   "outputs": [],
   "source": [
    "attn = Attention(hp.bert_hidden_size, hp.decoder_hidden_size, hp.attention_hidden_size)\n",
    "decoder = Decoder(hp.bert_vocab_size, hp.decoder_input_size, hp.bert_hidden_size,\n",
    "                  hp.decoder_hidden_size, hp.n_layers, hp.dropout, attn)\n",
    "encoder = BertModel.from_pretrained(hp.bert_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a1144c-86cd-47b7-8478-cbb0f73b9056",
   "metadata": {
    "id": "f6a1144c-86cd-47b7-8478-cbb0f73b9056"
   },
   "outputs": [],
   "source": [
    "model = Seq2Seq(encoder, decoder, hp.encoder_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd9f8ac-f0b8-4be7-8be9-11609e236cff",
   "metadata": {
    "id": "abd9f8ac-f0b8-4be7-8be9-11609e236cff"
   },
   "outputs": [],
   "source": [
    "if hp.sgd:\n",
    "    optimizer = optim.SGD(decoder.parameters(), weight_decay=hp.weight_decay, lr=hp.lr, momentum=hp.momentum)\n",
    "else:\n",
    "    optimizer = optim.Adam(decoder.parameters(), lr=hp.lr, weight_decay=hp.weight_decay)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6632ab1-3b24-4b25-ac15-61f45ec4c927",
   "metadata": {
    "id": "a6632ab1-3b24-4b25-ac15-61f45ec4c927",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b679d3-4e0b-424c-818d-d337f89b82dc",
   "metadata": {
    "id": "73b679d3-4e0b-424c-818d-d337f89b82dc"
   },
   "outputs": [],
   "source": [
    "models_dir = Path('/content/drive/MyDrive/NLP/models')\n",
    "if not models_dir.is_dir():\n",
    "    models_dir = Path('./models')\n",
    "model_save_dir = (models_dir / '{:%y-%m-%d-%H%M}-{}'.format(\n",
    "                  datetime.now(), hp.bert_model))\n",
    "model_save_dir.mkdir()\n",
    "json.dump({k:str(v) for k, v in hp.__dict__.items()},\n",
    "          (model_save_dir / 'hp.json').open('w'))\n",
    "pickle.dump(hp, (model_save_dir / 'hp.pkl').open('wb'))\n",
    "\n",
    "results = {'losses_train': [], 'losses_dev': []}\n",
    "last_dev_loss = None\n",
    "patience = hp.patience\n",
    "\n",
    "for epoch in range(hp.max_epochs):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, hp.clip)\n",
    "    dev_loss, bleu_score_i = eval(model, dev_loader, criterion)\n",
    "    print('End of epoch {}. Train loss is {:.3f}, Dev loss is {:.3f}, Bleu is {}'\n",
    "          .format(epoch+1, train_loss, dev_loss, bleu_score_i))\n",
    "    results['losses_train'].append(train_loss)\n",
    "    results['losses_dev'].append(dev_loss)\n",
    "    if epoch > 0:\n",
    "        if (dev_loss - last_dev_loss) > -0.00001:\n",
    "            patience -= 1\n",
    "            if patience <= 0: break\n",
    "        else:\n",
    "            patience = hp.patience\n",
    "    last_dev_loss = dev_loss\n",
    "torch.save(model, model_save_dir / 'best_model.pt')\n",
    "json.dump(results, (model_save_dir / 'results.json').open('w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YoV1CwttrBbk",
   "metadata": {
    "id": "YoV1CwttrBbk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "bertqg.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "QA-nlp",
   "language": "python",
   "name": "qa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0330c53a614143669eb753cc9d5431b3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08d0fb82f9aa4b2a8047cfb1fa089908": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e10eae4f2e44eeaa426ca46da3d76b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "30e051d7f5944bed926d8f1a29a903da": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42eabbf2c76443cca2621b3af7926637": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c3d26e9d73a54b32a48624df61d8ba55",
      "placeholder": "​",
      "style": "IPY_MODEL_dd2ea4ab0ba54d11aaf79ff19cfbe0a6",
      "value": " 571/571 [00:00&lt;00:00, 1.53kB/s]"
     }
    },
    "5213099ab0904d56bfa29610408427fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5b25bd5ed8bb40a7bf06ddd6d661865b",
       "IPY_MODEL_42eabbf2c76443cca2621b3af7926637"
      ],
      "layout": "IPY_MODEL_e04eb9d308d24d37983a110538c724b3"
     }
    },
    "5b25bd5ed8bb40a7bf06ddd6d661865b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_30e051d7f5944bed926d8f1a29a903da",
      "max": 571,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_faf2f83be9d14eb5af9449402951fd0b",
      "value": 571
     }
    },
    "5d46207da0b54f84a1cb7c12cdb04682": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9187f91691d7486fbd69a1bb90f1fe9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Downloading:  16%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d0dcc4e2f8d942b496fd36c544e98db9",
      "max": 1344997306,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5d46207da0b54f84a1cb7c12cdb04682",
      "value": 211256320
     }
    },
    "97e85d071a8c48c69993f3d91de06e13": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9187f91691d7486fbd69a1bb90f1fe9e",
       "IPY_MODEL_ba43d4279f8345aa8fa8b6f4442c7aa1"
      ],
      "layout": "IPY_MODEL_08d0fb82f9aa4b2a8047cfb1fa089908"
     }
    },
    "ba43d4279f8345aa8fa8b6f4442c7aa1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0330c53a614143669eb753cc9d5431b3",
      "placeholder": "​",
      "style": "IPY_MODEL_1e10eae4f2e44eeaa426ca46da3d76b7",
      "value": " 207M/1.34G [00:05&lt;00:29, 38.0MB/s]"
     }
    },
    "c3d26e9d73a54b32a48624df61d8ba55": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d0dcc4e2f8d942b496fd36c544e98db9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd2ea4ab0ba54d11aaf79ff19cfbe0a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e04eb9d308d24d37983a110538c724b3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "faf2f83be9d14eb5af9449402951fd0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
